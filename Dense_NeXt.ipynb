{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VJqwTvH6hqej"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.checkpoint as cp\n",
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class EnhancedInceptionModule(nn.Module):\n",
        "    def __init__(self, input_data_depth, output_data_depth, number_of_convolution_filters=32, max_kernel_size=7,\n",
        "                 dimensions_of_convolution=2):\n",
        "        super().__init__()\n",
        "        # The Member values are functions used in the inception, the convolution, max pool, and 1x1 convolution\n",
        "        # each made with three versions to handle one, two, and three dimensional data,\n",
        "\n",
        "        self.input_data_depth = input_data_depth\n",
        "        self.output_data_depth = output_data_depth\n",
        "        self.number_of_convolution_filters = number_of_convolution_filters\n",
        "        self.max_kernel_size = max_kernel_size\n",
        "        self.dimensions_of_convolution = dimensions_of_convolution\n",
        "\n",
        "        # Convolution layers,\n",
        "\n",
        "        self.convolution_1d = nn.Conv1d(in_channels=number_of_convolution_filters,\n",
        "                                        out_channels=number_of_convolution_filters, kernel_size=2, padding='same',\n",
        "                                        bias=False)\n",
        "        self.convolution_2d = nn.Conv2d(in_channels=number_of_convolution_filters,\n",
        "                                        out_channels=number_of_convolution_filters, kernel_size=2, padding='same',\n",
        "                                        bias=False)\n",
        "        self.convolution_3d = nn.Conv3d(in_channels=number_of_convolution_filters,\n",
        "                                        out_channels=number_of_convolution_filters, kernel_size=2, padding='same',\n",
        "                                        bias=False)\n",
        "\n",
        "        # 1x1 Convolution layers,\n",
        "\n",
        "        self.convolution_1d_1x1 = nn.Conv1d(in_channels=input_data_depth,\n",
        "                                            out_channels=number_of_convolution_filters, kernel_size=1, padding='same',\n",
        "                                             bias=False)\n",
        "        self.convolution_2d_1x1 = nn.Conv2d(in_channels=input_data_depth,\n",
        "                                            out_channels=number_of_convolution_filters, kernel_size=1, padding='same',\n",
        "                                             bias=False)\n",
        "        self.convolution_3d_1x1 = nn.Conv3d(in_channels=input_data_depth,\n",
        "                                            out_channels=number_of_convolution_filters, kernel_size=1, padding='same',\n",
        "                                             bias=False)\n",
        "\n",
        "        # Max pooling layers,\n",
        "\n",
        "        self.max_pool_1d = nn.MaxPool1d(kernel_size=3, stride=1, padding=1)\n",
        "        self.max_pool_2d = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "        self.max_pool_3d = nn.MaxPool3d(kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        self.max_kernel_size = max_kernel_size\n",
        "        self.dimensions_of_convolution = dimensions_of_convolution\n",
        "\n",
        "    def forward(self, input_data):\n",
        "\n",
        "        convolution = self.convolution_2d\n",
        "        max_pool = self.max_pool_2d\n",
        "        convolution_1x1 = self.convolution_2d_1x1\n",
        "\n",
        "        if self.dimensions_of_convolution == 1:\n",
        "            convolution = self.convolution_1d\n",
        "            max_pool = self.max_pool_1d\n",
        "            convolution_1x1 = self.convolution_1d_1x1\n",
        "\n",
        "        elif self.dimensions_of_convolution == 2:\n",
        "            convolution = self.convolution_2d\n",
        "            max_pool = self.max_pool_2d\n",
        "            convolution_1x1 = self.convolution_2d_1x1\n",
        "\n",
        "        elif self.dimensions_of_convolution == 3:\n",
        "            convolution = self.convolution_3d\n",
        "            max_pool = self.max_pool_3d\n",
        "            convolution_1x1 = self.convolution_3d_1x1\n",
        "\n",
        "        # an else statement to handle invalid dimensions, if the variable dimensions_of_convolution\n",
        "        # is not equal to 1 or 2 or 3.\n",
        "\n",
        "        else:\n",
        "            convolution_dimensional_error = \"Invalid convolution dimensions.\"\n",
        "            return convolution_dimensional_error\n",
        "\n",
        "        # The Max pool branch from the inception module (future reminder: put a link to the enhanced inception here)\n",
        "\n",
        "        convolution_input = convolution_1x1(input_data)\n",
        "        collective_data = convolution_1x1(input_data)\n",
        "\n",
        "        # Preparing the data for the iteration of convolution operation.\n",
        "\n",
        "        max_pool_output = max_pool(input_data)\n",
        "        convolution_1x1_output = convolution_1x1(max_pool_output)\n",
        "        collective_data = torch.cat((collective_data, convolution_1x1_output), 1)\n",
        "\n",
        "        # Iterating the convolution operation over the data (max_kernel_size - 1) times,\n",
        "        # Explanation:\n",
        "        #\n",
        "        # Tensor height/width after convolution = (height/width before - kernel height/width)/ stride + 1\n",
        "        # more concisely H/W_out = (H/W_in - H/W_kernel)/s +1\n",
        "        # at H/W_kernel = 2, s = 1\n",
        "        #\n",
        "        # H/W_out = ((H/W_in - 2)/ 1 + 1\n",
        "        #\n",
        "        # H/W_out = H/W_in - 1\n",
        "        #\n",
        "        # Therefore, to do a 7x7 convolution, where a 7x7 partition of the tensor is reduced\n",
        "        # to a single 1x1 square, requires 6 2x2 convolutions, and a 5x5 requires 4,\n",
        "        # a 3x3 requires 2.\n",
        "        #\n",
        "        # and a result, it is self-evident from the general pattern beforehand established,\n",
        "        # that a convolution of Kernel size K, requires K-1 (2x2) convolutions.\n",
        "        # ( or 1x2 or 2x2x2 for one-dimensional and three-dimensional convolutions.\n",
        "\n",
        "        for i in range(self.max_kernel_size - 1):\n",
        "          convolution.in_channels = collective_data.size(dim=1)\n",
        "          convolution_output = convolution(convolution_input)\n",
        "          collective_data = torch.cat((collective_data, convolution_output), 1)\n",
        "          convolution_input = convolution_output\n",
        "\n",
        "        # Applying 1x1 convolution to change the depth of the collective_data as to match the\n",
        "        # desired output depth.\n",
        "\n",
        "        if self.dimensions_of_convolution == 1:\n",
        "            output_1x1_convolution = nn.Conv1d(in_channels=collective_data.size(dim=1),\n",
        "                                               out_channels=self.output_data_depth, kernel_size=1, padding='same',\n",
        "                                               bias=False)\n",
        "            return output_1x1_convolution(collective_data)\n",
        "\n",
        "        elif self.dimensions_of_convolution == 2:\n",
        "            output_1x1_convolution = nn.Conv2d(in_channels=collective_data.size(dim=1),\n",
        "                                               out_channels=self.output_data_depth, kernel_size=1, padding='same',\n",
        "                                               bias=False)\n",
        "            return output_1x1_convolution(collective_data)\n",
        "\n",
        "        else:\n",
        "            output_1x1_convolution = nn.Conv3d(in_channels=collective_data.size(dim=1),\n",
        "                                               out_channels=self.output_data_depth, kernel_size=1, padding='same',\n",
        "                                               bias=False)\n",
        "            return output_1x1_convolution(collective_data)\n"
      ],
      "metadata": {
        "id": "EDOPzrk8k_hl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _batch_norm_function_factory(batch_norm, relu, convolution):\n",
        "    def batch_norm_function(*inputs):\n",
        "        concatenated_features = torch.cat(inputs, 1)\n",
        "        bottleneck_output = convolution(relu(batch_norm(concatenated_features)))\n",
        "        return bottleneck_output\n",
        "\n",
        "    return batch_norm_function"
      ],
      "metadata": {
        "id": "EX7TweMCiG1-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseLayer(nn.Module):\n",
        "    def __init__(self, number_of_input_features, growth_rate, batch_norm_size, drop_rate,\n",
        "                 model_dimensions_of_convolution, efficient=False):\n",
        "        super(DenseLayer, self).__init__()\n",
        "        self.number_of_input_features = number_of_input_features\n",
        "        self.growth_rate = growth_rate\n",
        "        self.batch_norm_size = batch_norm_size\n",
        "        self.drop_rate = drop_rate\n",
        "        self.model_dimensions_of_convolution = model_dimensions_of_convolution\n",
        "        self.efficient = efficient\n",
        "        \n",
        "        self.add_module('batch_norm_1_1d', nn.BatchNorm1d(number_of_input_features)),\n",
        "        self.add_module('batch_norm_1_2d', nn.BatchNorm2d(number_of_input_features)),\n",
        "        self.add_module('batch_norm_1_3d', nn.BatchNorm3d(number_of_input_features)),\n",
        "\n",
        "        self.add_module('relu1', nn.ReLU(inplace=True)),\n",
        "\n",
        "        self.add_module('convolution_1d_1x1', nn.Conv1d(number_of_input_features, batch_norm_size * growth_rate,\n",
        "                                                        kernel_size=1, stride=1, bias=False)),\n",
        "        self.add_module('convolution_2d_1x1', nn.Conv2d(number_of_input_features, batch_norm_size * growth_rate,\n",
        "                                                        kernel_size=1, stride=1, bias=False)),\n",
        "        self.add_module('convolution_3d_1x1', nn.Conv3d(number_of_input_features, batch_norm_size * growth_rate,\n",
        "                                                        kernel_size=1, stride=1, bias=False)),\n",
        "\n",
        "        self.add_module('batch_norm_2_1d', nn.BatchNorm1d(batch_norm_size * growth_rate)),\n",
        "        self.add_module('batch_norm_2_2d', nn.BatchNorm2d(batch_norm_size * growth_rate)),\n",
        "        self.add_module('batch_norm_2_3d', nn.BatchNorm3d(batch_norm_size * growth_rate)),\n",
        "\n",
        "        self.add_module('relu2', nn.ReLU(inplace=True)),\n",
        "\n",
        "        self.add_module('inception',\n",
        "                        EnhancedInceptionModule(\n",
        "                            input_data_depth=batch_norm_size * growth_rate,\n",
        "                            output_data_depth=growth_rate,\n",
        "                            number_of_convolution_filters=16,\n",
        "                            max_kernel_size=11,\n",
        "                            dimensions_of_convolution=model_dimensions_of_convolution)),\n",
        "        self.drop_rate = drop_rate\n",
        "        self.efficient = efficient\n",
        "        self.model_dimensions_of_convolution = model_dimensions_of_convolution\n",
        "\n",
        "    def forward(self, *previous_features):\n",
        "\n",
        "        batch_norm_function = _batch_norm_function_factory(batch_norm=self.batch_norm_1_2d,\n",
        "                                                           relu=self.relu1,\n",
        "                                                           convolution=self.convolution_2d_1x1)\n",
        "\n",
        "        if self.model_dimensions_of_convolution == 1:\n",
        "            batch_norm_function = _batch_norm_function_factory(batch_norm=self.batch_norm_1_1d,\n",
        "                                                               relu=self.relu1,\n",
        "                                                               convolution=self.convolution_1d_1x1)\n",
        "        elif self.model_dimensions_of_convolution == 3:\n",
        "            batch_norm_function = _batch_norm_function_factory(batch_norm=self.batch_norm_1_3d,\n",
        "                                                               relu=self.relu1,\n",
        "                                                               convolution=self.convolution_3d_1x1)\n",
        "\n",
        "        if self.efficient and any(previous_feature.requires_grad for previous_feature in previous_features):\n",
        "            bottleneck_output = cp.checkpoint(batch_norm_function, *previous_features)\n",
        "        else:\n",
        "            bottleneck_output = batch_norm_function(*previous_features)\n",
        "\n",
        "        new_features = self.inception(self.relu2(self.batch_norm_2_2d(bottleneck_output)))\n",
        "        \n",
        "        if self.model_dimensions_of_convolution == 1:\n",
        "            new_features = self.inception(self.relu2(self.batch_norm_2_1d(bottleneck_output)))\n",
        "            \n",
        "        elif self.model_dimensions_of_convolution == 3:\n",
        "            new_features = self.inception(self.relu2(self.batch_norm_2_3d(bottleneck_output)))\n",
        "           \n",
        "        if self.drop_rate > 0:\n",
        "            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n",
        "        return new_features"
      ],
      "metadata": {
        "id": "uuBguvrRiOPG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class _Transition(nn.Module):\n",
        "    def __init__(self, number_of_input_features, num_output_features, model_dimensions_of_convolution):\n",
        "        super(_Transition, self).__init__()\n",
        "        self.number_of_input_features = number_of_input_features\n",
        "        self.num_output_features = num_output_features\n",
        "        self.model_dimensions_of_convolution = model_dimensions_of_convolution\n",
        "\n",
        "        self.add_module('batch_norm_1d', nn.BatchNorm1d(number_of_input_features))\n",
        "        self.add_module('batch_norm_2d', nn.BatchNorm2d(number_of_input_features))\n",
        "        self.add_module('batch_norm_3d', nn.BatchNorm3d(number_of_input_features))\n",
        "\n",
        "        self.add_module('relu', nn.ReLU(inplace=True))\n",
        "\n",
        "        self.add_module('convolution_1x1_1d', nn.Conv1d(number_of_input_features, num_output_features,\n",
        "                                                        kernel_size=1, stride=1, bias=False))\n",
        "        self.add_module('convolution_1x1_2d', nn.Conv2d(number_of_input_features, num_output_features,\n",
        "                                                        kernel_size=1, stride=1, bias=False))\n",
        "        self.add_module('convolution_1x1_3d', nn.Conv3d(number_of_input_features, num_output_features,\n",
        "                                                        kernel_size=1, stride=1, bias=False))\n",
        "\n",
        "        self.add_module('average_pool_1d', nn.AvgPool1d(kernel_size=2, stride=2))\n",
        "        self.add_module('average_pool_2d', nn.AvgPool2d(kernel_size=2, stride=2))\n",
        "        self.add_module('average_pool_3d', nn.AvgPool3d(kernel_size=2, stride=2))\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        if self.model_dimensions_of_convolution == 1:\n",
        "            return self.average_pool_1d(self.convolution_1x1_1d(self.relu(self.batch_norm_1d(input_data))))\n",
        "        elif self.model_dimensions_of_convolution == 2:\n",
        "            return self.average_pool_2d(self.convolution_1x1_2d(self.relu(self.batch_norm_2d(input_data))))\n",
        "        elif self.model_dimensions_of_convolution == 3:\n",
        "            return self.average_pool_3d(self.convolution_1x1_3d(self.relu(self.batch_norm_3d(input_data))))\n",
        "\n",
        "        # an else statement to handle invalid dimensions, if the variable dimensions_of_convolution\n",
        "        # is not equal to 1 or 2 or 3.\n",
        "\n",
        "        else:\n",
        "            convolution_dimensional_error = \"Invalid convolution dimensions.\"\n",
        "            return convolution_dimensional_error"
      ],
      "metadata": {
        "id": "bkSmcgkhiSGd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class _DenseBlock(nn.Module):\n",
        "    def __init__(self, number_of_layers, number_of_input_features, batch_norm_size, growth_rate,\n",
        "                 drop_rate, model_dimensions_of_convolution, efficient=False):\n",
        "        super(_DenseBlock, self).__init__()\n",
        "        self.number_of_layers = number_of_layers\n",
        "        self.number_of_input_features = number_of_input_features\n",
        "        self.batch_norm_size = batch_norm_size\n",
        "        self.growth_rate = growth_rate\n",
        "        self.drop_rate = drop_rate\n",
        "        self.model_dimensions_of_convolution = model_dimensions_of_convolution\n",
        "        self.efficient = efficient\n",
        "        self.dense_layer = DenseLayer(number_of_input_features=number_of_input_features,\n",
        "                                       growth_rate=growth_rate, batch_norm_size=batch_norm_size,\n",
        "                                       model_dimensions_of_convolution=model_dimensions_of_convolution,\n",
        "                                       drop_rate=drop_rate, efficient=efficient\n",
        "                                       )\n",
        "        self.number_of_layers = number_of_layers\n",
        "\n",
        "    def forward(self, initial_features):\n",
        "        features = [initial_features]\n",
        "        for name, layer in self.named_children():\n",
        "            new_features = layer(*features)\n",
        "            features.append(new_features)\n",
        "        return torch.cat(features, 1)\n",
        "\n",
        "    \"\"\"\n",
        "    def forward(self, initial_features):\n",
        "        features = torch.tensor(initial_features)\n",
        "        for i in range(self.number_of_layers):\n",
        "            new_features = self.dense_layer(features)\n",
        "            features = torch.cat((features, new_features), dim=1)\n",
        "            self.dense_layer.number_of_input_features += i * self.growth_rate\n",
        "        return features\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "6z0Yd9wAle4W"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseNeXt(nn.Module):\n",
        "    r\"\"\"DenseNet-BC model class, based on\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`\n",
        "    Args:\n",
        "        growth_rate (int) - how many filters to add each layer (`k` in paper)\n",
        "        dense_block_configuration (list of 3 or 4 ints) - how many layers in each pooling block\n",
        "        number_of_initial_features (int) - the number of filters to learn in the first convolution layer\n",
        "        batch_norm_size (int) - multiplicative factor for number of bottle neck layers\n",
        "            (i.e. batch_norm_size * k features in the bottleneck layer)\n",
        "        drop_rate (float) - dropout rate after each dense layer\n",
        "        number_of_classes (int) - number of classification classes\n",
        "        small_inputs (bool) - set to True if images are 32x32. Otherwise assumes images are larger.\n",
        "        efficient (bool) - set to True to use checkpointing. Much more memory efficient, but slower.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_data_depth=3, growth_rate=12, dense_block_configuration=(16, 16, 16), compression=0.5,\n",
        "                 number_of_initial_features=24, batch_norm_size=4, drop_rate=0, number_of_classes=10,\n",
        "                 model_dimensions_of_convolution=2, small_inputs=True, efficient=False, inception_convolution_filters=16\n",
        "                 ):\n",
        "        super(DenseNeXt, self).__init__()\n",
        "        assert 0 < compression <= 1, 'compression of DenseNeXt should be between 0 and 1'\n",
        "        assert 1 <= model_dimensions_of_convolution <= 3, 'model_dimensions_of_convolution should be between 1 and 3'\n",
        "        \n",
        "        self.input_data_depth = input_data_depth\n",
        "        self.growth_rate = growth_rate\n",
        "        self.dense_block_configuration = dense_block_configuration\n",
        "        self.compression = compression\n",
        "        self.number_of_initial_features = number_of_initial_features\n",
        "        self.batch_norm_size = batch_norm_size\n",
        "        self.drop_rate = drop_rate\n",
        "        self.number_of_classes = number_of_classes\n",
        "        self.model_dimensions_of_convolution = model_dimensions_of_convolution\n",
        "        self.small_inputs = small_inputs\n",
        "        self.small_inputs = small_inputs\n",
        "        self.inception_convolution_filters = inception_convolution_filters\n",
        "\n",
        "        if small_inputs:\n",
        "            self.layers = nn.Sequential(OrderedDict([('initial_inception', EnhancedInceptionModule(input_data_depth=input_data_depth,\n",
        "                                                                  output_data_depth=number_of_initial_features,\n",
        "                                                                  number_of_convolution_filters=inception_convolution_filters,\n",
        "                                                                  dimensions_of_convolution=model_dimensions_of_convolution,\n",
        "                                                                  max_kernel_size=7\n",
        "                                                                  ))]))\n",
        "        else:\n",
        "            self.layers.add_module('initial_inception', EnhancedInceptionModule(input_data_depth=input_data_depth,\n",
        "                                                                  output_data_depth=number_of_initial_features,\n",
        "                                                                  number_of_convolution_filters=inception_convolution_filters,\n",
        "                                                                  dimensions_of_convolution=model_dimensions_of_convolution,\n",
        "                                                                  max_kernel_size=7\n",
        "                                                                  ))\n",
        "            if model_dimensions_of_convolution == 1:\n",
        "                self.layers.add_module('initial_batch_norm', nn.BatchNorm1d(number_of_initial_features))\n",
        "                self.layers.add_module('initial_max_pool',\n",
        "                                      nn.MaxPool1d(kernel_size=3, stride=2, padding=1, ceil_mode=False))\n",
        "            elif model_dimensions_of_convolution == 2:\n",
        "                self.layers.add_module('initial_batch_norm', nn.BatchNorm2d(number_of_initial_features))\n",
        "                self.layers.add_module('initial_max_pool',\n",
        "                                      nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=False))\n",
        "            elif model_dimensions_of_convolution == 3:\n",
        "                self.layers.add_module('initial_batch_norm', nn.BatchNorm3d(number_of_initial_features))\n",
        "                self.layers.add_module('initial_max_pool',\n",
        "                                      nn.MaxPool3d(kernel_size=3, stride=2, padding=1, ceil_mode=False))\n",
        "\n",
        "            self.layers.add_module('initial_ReLU', nn.ReLU(inplace=True))\n",
        "\n",
        "        number_of_features = number_of_initial_features\n",
        "        for i, number_of_layers in enumerate(dense_block_configuration):\n",
        "            block = _DenseBlock(\n",
        "                number_of_layers=number_of_layers,\n",
        "                number_of_input_features=number_of_features,\n",
        "                batch_norm_size=batch_norm_size,\n",
        "                growth_rate=growth_rate,\n",
        "                drop_rate=drop_rate,\n",
        "                efficient=efficient,\n",
        "                model_dimensions_of_convolution=model_dimensions_of_convolution\n",
        "            )\n",
        "            self.layers.add_module('dense_block_%d' % (i + 1), block)\n",
        "\n",
        "            number_of_features = number_of_features + number_of_layers * growth_rate\n",
        "            if i != len(dense_block_configuration) - 1:\n",
        "                transition = _Transition(number_of_input_features=number_of_features,\n",
        "                                         num_output_features=int(number_of_features * compression),\n",
        "                                         model_dimensions_of_convolution=model_dimensions_of_convolution\n",
        "                                         )\n",
        "                self.layers.add_module('transition_%d' % (i + 1), transition)\n",
        "                number_of_features = int(number_of_features * compression)\n",
        "\n",
        "        if model_dimensions_of_convolution == 1:\n",
        "            self.layers.add_module('final_batch_norm', nn.BatchNorm1d(number_of_initial_features))\n",
        "\n",
        "        elif model_dimensions_of_convolution == 2:\n",
        "            self.layers.add_module('final_batch_norm', nn.BatchNorm2d(number_of_initial_features))\n",
        "\n",
        "        elif model_dimensions_of_convolution == 3:\n",
        "            self.layers.add_module('final_batch_norm', nn.BatchNorm3d(number_of_initial_features))\n",
        "\n",
        "        self.classifier = nn.Linear(number_of_features, number_of_classes)\n",
        "        # TODO: try convolution as a classifier\n",
        "\n",
        "        for name, parameter in self.named_parameters():\n",
        "            if 'conv' in name and 'weight' in name:\n",
        "                dimensions = [parameter.size]\n",
        "                n = parameter.size(0)\n",
        "                for i in range(2, len(dimensions)):\n",
        "                    n *= parameter.size(i)\n",
        "                parameter.data.normal_().mul_(math.sqrt(2. / n))\n",
        "            elif 'norm' in name and 'weight' in name:\n",
        "                parameter.data.fill_(1)\n",
        "            elif 'norm' in name and 'bias' in name:\n",
        "                parameter.data.fill_(0)\n",
        "            elif 'classifier' in name and 'bias' in name:\n",
        "                parameter.data.fill_(0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.layers(x)\n",
        "        out = F.relu(features, inplace=True)\n",
        "        out = F.adaptive_avg_pool2d(out, (1, 1))\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.classifier(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "IAgYKLa3iYNN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = DenseNeXt()\n",
        "print(net)\n",
        "\n",
        "# number_of_input_features, growth_rate, batch_norm_size, drop_rate,\n",
        "# model_dimensions_of_convolution, efficient=False"
      ],
      "metadata": {
        "id": "fjYQk-zxixYm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7f15e1d-c330-4b8e-a088-3a4acf1e2568"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DenseNeXt(\n",
            "  (layers): Sequential(\n",
            "    (initial_inception): EnhancedInceptionModule(\n",
            "      (convolution_1d): Conv1d(16, 16, kernel_size=(2,), stride=(1,), padding=same, bias=False)\n",
            "      (convolution_2d): Conv2d(16, 16, kernel_size=(2, 2), stride=(1, 1), padding=same, bias=False)\n",
            "      (convolution_3d): Conv3d(16, 16, kernel_size=(2, 2, 2), stride=(1, 1, 1), padding=same, bias=False)\n",
            "      (convolution_1d_1x1): Conv1d(3, 16, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
            "      (convolution_2d_1x1): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
            "      (convolution_3d_1x1): Conv3d(3, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), padding=same, bias=False)\n",
            "      (max_pool_1d): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "      (max_pool_2d): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "      (max_pool_3d): MaxPool3d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (dense_block_1): _DenseBlock(\n",
            "      (dense_layer): DenseLayer(\n",
            "        (batch_norm_1_1d): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (batch_norm_1_2d): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (batch_norm_1_3d): BatchNorm3d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (convolution_1d_1x1): Conv1d(24, 48, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (convolution_2d_1x1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (convolution_3d_1x1): Conv3d(24, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (batch_norm_2_1d): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (batch_norm_2_2d): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (batch_norm_2_3d): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (inception): EnhancedInceptionModule(\n",
            "          (convolution_1d): Conv1d(16, 16, kernel_size=(2,), stride=(1,), padding=same, bias=False)\n",
            "          (convolution_2d): Conv2d(16, 16, kernel_size=(2, 2), stride=(1, 1), padding=same, bias=False)\n",
            "          (convolution_3d): Conv3d(16, 16, kernel_size=(2, 2, 2), stride=(1, 1, 1), padding=same, bias=False)\n",
            "          (convolution_1d_1x1): Conv1d(48, 16, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
            "          (convolution_2d_1x1): Conv2d(48, 16, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
            "          (convolution_3d_1x1): Conv3d(48, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), padding=same, bias=False)\n",
            "          (max_pool_1d): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "          (max_pool_2d): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "          (max_pool_3d): MaxPool3d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (transition_1): _Transition(\n",
            "      (batch_norm_1d): BatchNorm1d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (batch_norm_2d): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (batch_norm_3d): BatchNorm3d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (convolution_1x1_1d): Conv1d(216, 108, kernel_size=(1,), stride=(1,), bias=False)\n",
            "      (convolution_1x1_2d): Conv2d(216, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (convolution_1x1_3d): Conv3d(216, 108, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (average_pool_1d): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
            "      (average_pool_2d): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "      (average_pool_3d): AvgPool3d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (dense_block_2): _DenseBlock(\n",
            "      (dense_layer): DenseLayer(\n",
            "        (batch_norm_1_1d): BatchNorm1d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (batch_norm_1_2d): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (batch_norm_1_3d): BatchNorm3d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (convolution_1d_1x1): Conv1d(108, 48, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (convolution_2d_1x1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (convolution_3d_1x1): Conv3d(108, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (batch_norm_2_1d): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (batch_norm_2_2d): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (batch_norm_2_3d): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (inception): EnhancedInceptionModule(\n",
            "          (convolution_1d): Conv1d(16, 16, kernel_size=(2,), stride=(1,), padding=same, bias=False)\n",
            "          (convolution_2d): Conv2d(16, 16, kernel_size=(2, 2), stride=(1, 1), padding=same, bias=False)\n",
            "          (convolution_3d): Conv3d(16, 16, kernel_size=(2, 2, 2), stride=(1, 1, 1), padding=same, bias=False)\n",
            "          (convolution_1d_1x1): Conv1d(48, 16, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
            "          (convolution_2d_1x1): Conv2d(48, 16, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
            "          (convolution_3d_1x1): Conv3d(48, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), padding=same, bias=False)\n",
            "          (max_pool_1d): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "          (max_pool_2d): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "          (max_pool_3d): MaxPool3d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (transition_2): _Transition(\n",
            "      (batch_norm_1d): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (batch_norm_2d): BatchNorm2d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (batch_norm_3d): BatchNorm3d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (convolution_1x1_1d): Conv1d(300, 150, kernel_size=(1,), stride=(1,), bias=False)\n",
            "      (convolution_1x1_2d): Conv2d(300, 150, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (convolution_1x1_3d): Conv3d(300, 150, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "      (average_pool_1d): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
            "      (average_pool_2d): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "      (average_pool_3d): AvgPool3d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (dense_block_3): _DenseBlock(\n",
            "      (dense_layer): DenseLayer(\n",
            "        (batch_norm_1_1d): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (batch_norm_1_2d): BatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (batch_norm_1_3d): BatchNorm3d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace=True)\n",
            "        (convolution_1d_1x1): Conv1d(150, 48, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (convolution_2d_1x1): Conv2d(150, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (convolution_3d_1x1): Conv3d(150, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (batch_norm_2_1d): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (batch_norm_2_2d): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (batch_norm_2_3d): BatchNorm3d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace=True)\n",
            "        (inception): EnhancedInceptionModule(\n",
            "          (convolution_1d): Conv1d(16, 16, kernel_size=(2,), stride=(1,), padding=same, bias=False)\n",
            "          (convolution_2d): Conv2d(16, 16, kernel_size=(2, 2), stride=(1, 1), padding=same, bias=False)\n",
            "          (convolution_3d): Conv3d(16, 16, kernel_size=(2, 2, 2), stride=(1, 1, 1), padding=same, bias=False)\n",
            "          (convolution_1d_1x1): Conv1d(48, 16, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
            "          (convolution_2d_1x1): Conv2d(48, 16, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
            "          (convolution_3d_1x1): Conv3d(48, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), padding=same, bias=False)\n",
            "          (max_pool_1d): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "          (max_pool_2d): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "          (max_pool_3d): MaxPool3d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (final_batch_norm): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (classifier): Linear(in_features=342, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    }
  ]
}